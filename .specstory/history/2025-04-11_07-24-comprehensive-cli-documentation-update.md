<!-- Generated by SpecStory -->

# Comprehensive CLI Documentation Update (2025-04-11 03:24:55)

_**User**_

Update my @cli documentation to be more complete. Make sure the missing documents from @cli-overview.md are implemented. Add @yargs context. Make it extremely comprehensive. Add extra documents as needed.

---

_**Assistant**_



---

Your Lordship, I'll update your CLI documentation to be comprehensive and implement all missing documents. Based on the cli-overview.md references, we need to create workflow-orchestration.md and benchmarking.md, while enhancing the existing documents.

---

Read file: documentation/cli/command-structure.md

---

Read file: documentation/cli/cost-management.md

---

Now I'll create the missing documents based on the existing structure and content:

---

```diff
- 
+ # CLI Workflow Orchestration
+ 
+ The Obsidian Magic CLI implements a flexible workflow orchestration system that efficiently processes conversations with different strategies based on context and user preferences.
+ 
+ ## Processing Modes
+ 
+ The CLI supports multiple processing modes that determine how files are handled:
+ 
+ ```bash
+ # Automatic mode processes all files with minimal interaction
+ tag-conversations tag ./convos/ --mode=auto
+ 
+ # Interactive mode prompts for confirmation on each file
+ tag-conversations tag ./convos/ --mode=interactive
+ 
+ # Differential mode only processes files needing updates
+ tag-conversations tag ./convos/ --mode=differential
+ ```
+ 
+ ### Auto Mode
+ 
+ Auto mode processes all files without requiring user intervention:
+ 
+ - Processes all files sequentially or in parallel based on concurrency settings
+ - Applies consistent tagging based on global confidence thresholds
+ - Outputs summary statistics after completion
+ - Ideal for batch processing of large conversation collections
+ 
+ ### Interactive Mode
+ 
+ Interactive mode provides a guided workflow with user decision points:
+ 
+ - Previews each file before processing
+ - Displays token usage and cost estimates per file
+ - Allows skipping individual files
+ - Provides options to review and modify suggested tags
+ - Supports manual tag editing for fine-tuned control
+ 
+ ### Differential Mode
+ 
+ Differential mode intelligently processes only files needing updates:
+ 
+ - Scans frontmatter of existing files for tag presence
+ - Detects files with missing or incomplete tags
+ - Prioritizes files by modification date
+ - Skips already well-tagged conversations
+ - Provides significant time and cost savings for large repositories
+ 
+ ## Processing Pipeline
+ 
+ The CLI implements a sophisticated processing pipeline for each conversation:
+ 
+ ### Pre-processing Steps
+ 
+ 1. **File Discovery**: Recursively scans directories for Markdown files
+ 2. **Format Validation**: Validates file structure and frontmatter
+ 3. **Content Extraction**: Parses conversation content for processing
+ 4. **Token Estimation**: Calculates token counts for each file
+ 5. **Batch Planning**: Organizes files into efficient processing batches
+ 
+ ### Core Processing Stages
+ 
+ 1. **Context Preparation**: Extracts relevant context from conversations
+ 2. **Prompt Construction**: Builds optimized prompts for classification
+ 3. **API Processing**: Submits prompts to OpenAI API with appropriate parameters
+ 4. **Response Parsing**: Extracts structured data from API responses
+ 5. **Validation**: Ensures classification results meet quality criteria
+ 
+ ### Post-processing Steps
+ 
+ 1. **Tag Application**: Updates files with new tag metadata
+ 2. **Statistics Gathering**: Collects usage and performance metrics
+ 3. **Report Generation**: Creates detailed processing reports
+ 4. **Cache Management**: Updates caching system for future efficiency
+ 
+ ## Concurrency Management
+ 
+ The CLI implements adaptive concurrency for optimal throughput:
+ 
+ ```bash
+ # Set specific concurrency level
+ tag-conversations tag ./convos/ --concurrency=5
+ 
+ # Automatic concurrency based on system capabilities
+ tag-conversations tag ./convos/ --concurrency=auto
+ ```
+ 
+ ### Concurrency Features
+ 
+ - Parallel processing of multiple files within rate limits
+ - Adaptive throttling based on API response times
+ - Graceful handling of rate limiting and quota errors
+ - Progress tracking for concurrent operations
+ - Resource usage optimization based on system capabilities
+ 
+ ## Queue Management
+ 
+ The processing system implements sophisticated queue management:
+ 
+ ### Queue Features
+ 
+ - Priority-based processing queue with configurable ordering
+ - Resumable processing sessions for interrupted runs
+ - Checkpoint system for fail-safe operation
+ - Intelligent retry logic with exponential backoff
+ - Session persistence for long-running operations
+ 
+ ### Queue Commands
+ 
+ ```bash
+ # Resume a previously paused or failed queue
+ tag-conversations resume --session=latest
+ 
+ # View current queue status
+ tag-conversations queue status
+ 
+ # Clear all pending queue items
+ tag-conversations queue clear
+ ```
+ 
+ ## File Selection Strategies
+ 
+ The CLI supports sophisticated file selection patterns:
+ 
+ ### Path Selection
+ 
+ ```bash
+ # Process specific files
+ tag-conversations tag file1.md file2.md
+ 
+ # Process all files in a directory
+ tag-conversations tag ./convos/
+ 
+ # Process files matching a glob pattern
+ tag-conversations tag "./convos/**/*.md"
+ 
+ # Exclude specific patterns
+ tag-conversations tag "./convos/" --exclude="**/archive/**"
+ ```
+ 
+ ### Content-based Selection
+ 
+ ```bash
+ # Process only files containing specific content
+ tag-conversations tag "./convos/" --contains="machine learning"
+ 
+ # Process files based on frontmatter conditions
+ tag-conversations tag "./convos/" --filter="tags.length < 3"
+ 
+ # Process files modified after a certain date
+ tag-conversations tag "./convos/" --modified-after="2023-01-01"
+ ```
+ 
+ ## Error Handling
+ 
+ The CLI implements robust error handling to ensure smooth operation:
+ 
+ ### Error Strategies
+ 
+ - Graceful degradation for API failures
+ - Automatic retries with exponential backoff
+ - Detailed error logging with context
+ - Session recovery from checkpoint data
+ - Fallback models for reliability
+ 
+ ### Error Reporting
+ 
+ ```bash
+ # Enable verbose error reporting
+ tag-conversations tag ./convos/ --verbose-errors
+ 
+ # Save error logs to file
+ tag-conversations tag ./convos/ --error-log=errors.json
+ ```
+ 
+ ## Workflow Customization
+ 
+ The CLI supports workflow customization through configuration profiles:
+ 
+ ### Profile Management
+ 
+ ```bash
+ # Create a named workflow profile
+ tag-conversations profiles create fast-tagging --model=gpt-3.5-turbo --concurrency=5
+ 
+ # Use a saved profile
+ tag-conversations tag ./convos/ --profile=fast-tagging
+ 
+ # List available profiles
+ tag-conversations profiles list
+ ```
+ 
+ ### Custom Workflows
+ 
+ Create specialized workflows for different use cases:
+ 
+ - **Quick-scan**: Rapid classification with lower precision
+ - **Deep-analysis**: Thorough classification with high precision
+ - **Batch-optimized**: Cost-efficient processing for large collections
+ - **Interactive-review**: High-engagement workflow with user review steps 
```

---

```diff
- 
+ # CLI Benchmarking Capabilities
+ 
+ The Obsidian Magic CLI includes a comprehensive benchmarking system to evaluate model performance, accuracy, and cost-effectiveness across different configurations.
+ 
+ ## Benchmark Command
+ 
+ The CLI provides a dedicated benchmark command for performance evaluation:
+ 
+ ```bash
+ # Run basic benchmark
+ tag-conversations test --benchmark
+ 
+ # Run comprehensive benchmark with all models
+ tag-conversations test --benchmark --all-models
+ 
+ # Compare specific models
+ tag-conversations test --benchmark --models=gpt-3.5-turbo,gpt-4
+ ```
+ 
+ ## Benchmark Datasets
+ 
+ The benchmark system uses carefully curated test datasets:
+ 
+ ### Built-in Datasets
+ 
+ The CLI includes built-in benchmark datasets:
+ 
+ - **Standard**: General conversation sample with diverse topics (~100 files)
+ - **Edge-case**: Challenging conversations with ambiguous topics
+ - **Multilingual**: Conversations in multiple languages
+ - **Technical**: Specialized technical conversations
+ 
+ ```bash
+ # Run benchmark with specific dataset
+ tag-conversations test --benchmark --dataset=technical
+ ```
+ 
+ ### Custom Datasets
+ 
+ Users can define custom benchmark datasets:
+ 
+ ```bash
+ # Register a custom benchmark dataset
+ tag-conversations benchmark register-dataset ./my-dataset/ --name=my-custom-dataset
+ 
+ # Run benchmark with custom dataset
+ tag-conversations test --benchmark --dataset=my-custom-dataset
+ ```
+ 
+ ## Benchmark Metrics
+ 
+ The benchmark system evaluates performance across multiple dimensions:
+ 
+ ### Accuracy Metrics
+ 
+ - **Tag Precision**: Correctness of applied tags
+ - **Tag Recall**: Completeness of tag coverage
+ - **Classification F1-Score**: Combined precision and recall measure
+ - **Domain Accuracy**: Precision within specific domains
+ - **Confusion Matrix**: Detailed error analysis
+ 
+ ### Performance Metrics
+ 
+ - **Tokens per Conversation**: Average token usage per conversation
+ - **Processing Time**: Time required for different operations
+ - **Cost per Conversation**: Average cost per processed file
+ - **Cost per Tag**: Efficiency of tag generation
+ - **Throughput**: Files processed per minute
+ 
+ ### Reliability Metrics
+ 
+ - **Error Rate**: Frequency of processing failures
+ - **Retry Rate**: Frequency of API retries
+ - **Completion Rate**: Percentage of successfully processed files
+ - **Consistency**: Variance in classification results
+ 
+ ## Benchmark Reports
+ 
+ The CLI generates comprehensive reports from benchmark runs:
+ 
+ ### Report Formats
+ 
+ ```bash
+ # Generate HTML benchmark report
+ tag-conversations test --benchmark --report=html --output=benchmark-report.html
+ 
+ # Generate JSON data for further analysis
+ tag-conversations test --benchmark --report=json --output=benchmark-data.json
+ 
+ # Generate CSV for spreadsheet analysis
+ tag-conversations test --benchmark --report=csv --output=benchmark-results.csv
+ ```
+ 
+ ### Report Contents
+ 
+ - Executive summary with key findings
+ - Detailed performance breakdowns by model
+ - Cost analysis and comparisons
+ - Accuracy metrics with visualization
+ - Improvement recommendations
+ - Raw data for further analysis
+ 
+ ## Model Comparison
+ 
+ The benchmark system enables detailed model comparison:
+ 
+ ### Comparison Features
+ 
+ - Side-by-side model performance comparison
+ - Cost-benefit analysis for different models
+ - Performance/cost ratios
+ - Optimal model recommendations by task type
+ - Detailed error analysis by model
+ 
+ ```bash
+ # Compare specific models and generate comparison report
+ tag-conversations test --benchmark --models=gpt-3.5-turbo,gpt-4,claude-3-opus --compare --output=model-comparison.html
+ ```
+ 
+ ## Parameter Optimization
+ 
+ The benchmark system can optimize processing parameters:
+ 
+ ### Optimization Features
+ 
+ - Systematic testing of different parameter combinations
+ - Confidence threshold optimization
+ - Concurrency parameter tuning
+ - Token optimization strategy evaluation
+ - Automatic identification of optimal configuration
+ 
+ ```bash
+ # Run parameter optimization benchmark
+ tag-conversations test --benchmark --optimize-params --parameters=confidence,concurrency
+ ```
+ 
+ ## Continuous Benchmarking
+ 
+ The CLI supports automated regular benchmarking:
+ 
+ ### Automation Options
+ 
+ ```bash
+ # Schedule regular benchmark runs
+ tag-conversations benchmark schedule --frequency=weekly --dataset=standard --models=gpt-3.5-turbo,gpt-4
+ 
+ # View benchmark history
+ tag-conversations benchmark history
+ 
+ # Compare benchmark runs
+ tag-conversations benchmark compare --runs=latest,previous
+ ```
+ 
+ ## Custom Benchmark Scenarios
+ 
+ Create specialized benchmark scenarios for specific needs:
+ 
+ ### Scenario Configuration
+ 
+ ```bash
+ # Create custom benchmark scenario
+ tag-conversations benchmark create-scenario tagging-technical-content \
+   --dataset=technical \
+   --models=gpt-3.5-turbo,gpt-4 \
+   --params=max-tokens:1000,temperature:0.2
+ 
+ # Run custom benchmark scenario
+ tag-conversations benchmark run-scenario tagging-technical-content
+ ```
+ 
+ ## Integration Testing
+ 
+ The benchmark system includes integration testing capabilities:
+ 
+ ### Integration Tests
+ 
+ - End-to-end workflow testing
+ - API integration validation
+ - Error handling verification
+ - Performance regression testing
+ - Configuration validation
+ 
+ ```bash
+ # Run integration tests
+ tag-conversations test --integration
+ 
+ # Run specific integration test suite
+ tag-conversations test --integration --suite=api-handling
+ ```
+ 
+ ## Stress Testing
+ 
+ The CLI includes tools for stress testing the system:
+ 
+ ### Stress Test Features
+ 
+ - Large volume processing simulation
+ - Parallel processing stress testing
+ - API quota limit testing
+ - Error recovery validation
+ - System resource monitoring
+ 
+ ```bash
+ # Run stress test
+ tag-conversations test --stress-test --volume=1000 --concurrency=10
+ 
+ # Run targeted stress test
+ tag-conversations test --stress-test --focus=api-resilience
+ ```
+ 
+ ## Performance Analysis Tools
+ 
+ The CLI provides tools for detailed performance analysis:
+ 
+ ### Analysis Features
+ 
+ - Token usage breakdown by conversation type
+ - Cost attribution by classification stage
+ - Processing time distribution analysis
+ - Memory usage profiling
+ - Bottleneck identification
+ 
+ ```bash
+ # Generate performance analysis report
+ tag-conversations benchmark analyze-performance --last-run --output=performance-analysis.html
+ ```
+ 
+ ## Data Visualization
+ 
+ The benchmark reports include rich data visualization:
+ 
+ ### Visualization Types
+ 
+ - Performance comparison charts
+ - Cost distribution graphs
+ - Accuracy heatmaps
+ - Processing time histograms
+ - Tag distribution visualizations
+ 
+ The visualizations help identify patterns and make data-driven decisions about model selection and configuration optimization. 
```

---

Now I'll create a comprehensive file on yargs integration for Obsidian Magic CLI:

---

```diff
- 
+ # Yargs Implementation in Obsidian Magic CLI
+ 
+ The Obsidian Magic CLI leverages Yargs to create a powerful, user-friendly command-line interface with rich features, nested commands, and comprehensive help documentation.
+ 
+ ## Core Yargs Integration
+ 
+ The CLI architecture uses the latest version of Yargs with TypeScript for type-safe command definitions:
+ 
+ ```typescript
+ import yargs from 'yargs';
+ import { hideBin } from 'yargs/helpers';
+ 
+ export const cli = yargs(hideBin(process.argv))
+   .scriptName('tag-conversations')
+   .usage('$0 <command> [options]')
+   .strict()
+   .demandCommand(1, 'You must specify a command')
+   .recommendCommands()
+   .middleware(globalMiddleware)
+   .fail(handleFailure);
+ ```
+ 
+ ## Command Structure
+ 
+ The CLI implements a hierarchical command structure with Yargs:
+ 
+ ### Main Commands
+ 
+ ```typescript
+ // Main command registration
+ cli
+   .command(tagCommand)
+   .command(testCommand)
+   .command(configCommand)
+   .command(statsCommand)
+   .command(taxonomyCommand);
+ ```
+ 
+ ### Nested Commands
+ 
+ ```typescript
+ // Example of nested command structure
+ const configCommand = {
+   command: 'config <action>',
+   describe: 'Manage configuration settings',
+   builder: (yargs) => {
+     return yargs
+       .command({
+         command: 'set <key> <value>',
+         describe: 'Set a configuration value',
+         builder: (yargs) => {
+           return yargs
+             .positional('key', {
+               describe: 'Configuration key to set',
+               type: 'string'
+             })
+             .positional('value', {
+               describe: 'Value to set',
+               type: 'string'
+             });
+         },
+         handler: async (argv) => {
+           await configHandlers.setConfig(argv.key, argv.value);
+         }
+       })
+       .command({
+         command: 'get [key]',
+         describe: 'Get configuration value(s)',
+         builder: (yargs) => {
+           return yargs
+             .positional('key', {
+               describe: 'Configuration key to get (omit for all)',
+               type: 'string'
+             });
+         },
+         handler: async (argv) => {
+           await configHandlers.getConfig(argv.key);
+         }
+       });
+   },
+   handler: (argv) => {
+     // Show help when no subcommand is provided
+     if (argv.action === 'config') {
+       yargs.showHelp();
+     }
+   }
+ };
+ ```
+ 
+ ## Type-Safe Option Definitions
+ 
+ The CLI uses TypeScript to create type-safe option definitions:
+ 
+ ```typescript
+ // Type definitions for command options
+ interface TagCommandOptions {
+   mode: 'auto' | 'interactive' | 'differential';
+   model: string;
+   dryRun: boolean;
+   force: boolean;
+   concurrency: number;
+   tagMode: 'overwrite' | 'merge' | 'augment';
+   minConfidence: number;
+   maxCost: number;
+   onLimit: 'pause' | 'warn' | 'stop';
+   format: 'pretty' | 'json' | 'silent';
+   verbose: boolean;
+   output?: string;
+ }
+ 
+ // Type-safe command builder
+ const tagCommand = {
+   command: 'tag [paths..]',
+   describe: 'Tag conversations in the provided paths',
+   builder: (yargs: Argv<{}>): Argv<TagCommandOptions> => {
+     return yargs
+       .positional('paths', {
+         describe: 'Files or directories to process',
+         type: 'string',
+         array: true,
+         demandOption: true
+       })
+       .options({
+         mode: {
+           describe: 'Processing mode',
+           choices: ['auto', 'interactive', 'differential'] as const,
+           default: 'auto',
+           type: 'string'
+         },
+         model: {
+           describe: 'Model to use for classification',
+           type: 'string',
+           default: 'gpt-3.5-turbo'
+         },
+         // Other options...
+       });
+   },
+   handler: async (argv: ArgumentsCamelCase<TagCommandOptions>) => {
+     await tagHandler(argv);
+   }
+ };
+ ```
+ 
+ ## Command Middleware
+ 
+ The CLI leverages Yargs middleware for cross-cutting concerns:
+ 
+ ```typescript
+ // Global middleware applied to all commands
+ const globalMiddleware = (argv: Arguments) => {
+   // Setup logging based on log level
+   if (argv.logLevel) {
+     configureLogger(argv.logLevel);
+   }
+   
+   // Load environment variables
+   if (argv.envFile) {
+     dotenv.config({ path: argv.envFile });
+   } else {
+     dotenv.config();
+   }
+   
+   // Initialize global services
+   initializeServices(argv);
+   
+   return argv;
+ };
+ 
+ // Command-specific middleware
+ const tagCommandMiddleware = (argv: Arguments<TagCommandOptions>) => {
+   // Verify API credentials before processing
+   checkApiCredentials();
+   
+   // Normalize paths for processing
+   argv.paths = normalizePaths(argv.paths);
+   
+   return argv;
+ };
+ ```
+ 
+ ## Advanced Yargs Features
+ 
+ The CLI leverages advanced Yargs features for a polished user experience:
+ 
+ ### Progressive Disclosure
+ 
+ ```typescript
+ // Progressive disclosure example
+ const showAdvancedOptions = (argv: Arguments) => {
+   return argv.advanced || argv.expert;
+ };
+ 
+ yargs.options({
+   // Basic options always shown
+   model: {
+     describe: 'Model to use for classification',
+     type: 'string',
+     group: 'Basic Options:'
+   },
+   
+   // Advanced options only shown when requested
+   temperature: {
+     describe: 'Temperature setting for model',
+     type: 'number',
+     hidden: !showAdvancedOptions,
+     group: 'Advanced Options:'
+   },
+   maxTokens: {
+     describe: 'Maximum tokens for completion',
+     type: 'number',
+     hidden: !showAdvancedOptions,
+     group: 'Advanced Options:'
+   }
+ });
+ ```
+ 
+ ### Auto-completion
+ 
+ The CLI implements shell auto-completion using Yargs:
+ 
+ ```typescript
+ // Register completion command
+ yargs.completion('completion', 'Generate shell completion script');
+ 
+ // Custom completion logic for specific arguments
+ yargs.options({
+   model: {
+     describe: 'Model to use for classification',
+     type: 'string',
+     choices: getAvailableModels() // Dynamically generated choices
+   }
+ });
+ ```
+ 
+ ### Usage Instructions
+ 
+ The CLI provides rich usage examples:
+ 
+ ```typescript
+ // Configuring usage examples
+ yargs
+   .example('$0 tag ./conversations/', 'Tag all conversations in directory')
+   .example(
+     '$0 tag ./conversations/ --model=gpt-4',
+     'Use GPT-4 for tagging'
+   )
+   .example(
+     '$0 tag ./conversations/ --mode=interactive',
+     'Process files with interactive prompts'
+   );
+ ```
+ 
+ ### Validation
+ 
+ The CLI implements robust argument validation:
+ 
+ ```typescript
+ // Option validation
+ yargs.options({
+   minConfidence: {
+     describe: 'Minimum confidence threshold',
+     type: 'number',
+     default: 0.7,
+     check: (value) => {
+       if (value < 0 || value > 1) {
+         throw new Error('Confidence must be between 0 and 1');
+       }
+       return true;
+     }
+   },
+   maxCost: {
+     describe: 'Maximum budget for this run',
+     type: 'number',
+     check: (value) => {
+       if (value <= 0) {
+         throw new Error('Max cost must be greater than 0');
+       }
+       return true;
+     }
+   }
+ });
+ 
+ // Custom validator middleware
+ const validatePaths = (argv: Arguments<{ paths: string[] }>) => {
+   for (const path of argv.paths) {
+     if (!fs.existsSync(path)) {
+       throw new Error(`Path does not exist: ${path}`);
+     }
+   }
+   return argv;
+ };
+ ```
+ 
+ ## Error Handling
+ 
+ The CLI implements custom error handling for Yargs:
+ 
+ ```typescript
+ // Custom error handler
+ const handleFailure = (msg: string, err: Error, yargs: any) => {
+   if (err) {
+     if (process.env.DEBUG) {
+       console.error(chalk.red('Error:'), err);
+     } else {
+       console.error(chalk.red('Error:'), err.message);
+     }
+   } else {
+     console.error(chalk.red('Error:'), msg);
+   }
+   console.error('\nUse --help for more information');
+   process.exit(1);
+ };
+ ```
+ 
+ ## Help and Documentation
+ 
+ The CLI implements rich help documentation:
+ 
+ ```typescript
+ // Configure help output
+ yargs
+   .help('help', 'Show help')
+   .alias('help', 'h')
+   .updateStrings({
+     'Options:': chalk.bold('Options:'),
+     'Commands:': chalk.bold('Commands:'),
+     'Examples:': chalk.bold('Examples:')
+   })
+   .epilogue(
+     `For more information, visit the documentation:\n${chalk.blue('https://github.com/obsidian-magic/docs')}`
+   );
+ ```
+ 
+ ## Interactive Features
+ 
+ The CLI enhances Yargs with interactive features:
+ 
+ ```typescript
+ // Interactive command prompt example
+ import inquirer from 'inquirer';
+ 
+ const promptForModel = async (argv: Arguments) => {
+   if (argv.model) return argv;
+   
+   const { model } = await inquirer.prompt([
+     {
+       type: 'list',
+       name: 'model',
+       message: 'Select model for tagging:',
+       choices: [
+         { name: 'gpt-3.5-turbo ($0.56 estimated) - Recommended', value: 'gpt-3.5-turbo' },
+         { name: 'gpt-4-turbo-preview ($2.14 estimated) - Higher accuracy', value: 'gpt-4-turbo-preview' },
+         { name: 'gpt-4 ($4.28 estimated) - Legacy model', value: 'gpt-4' }
+       ]
+     }
+   ]);
+   
+   argv.model = model;
+   return argv;
+ };
+ ```
+ 
+ ## Configuration Integration
+ 
+ The CLI integrates configuration management with Yargs:
+ 
+ ```typescript
+ // Load config file and merge with command line arguments
+ import { cosmiconfig } from 'cosmiconfig';
+ 
+ const loadConfig = async (argv: Arguments) => {
+   const explorer = cosmiconfig('tag-conversations');
+   let config = {};
+   
+   // Try loading from specified config file
+   if (argv.config) {
+     const result = await explorer.load(argv.config);
+     config = result?.config || {};
+   } else {
+     // Search for config in standard locations
+     const result = await explorer.search();
+     config = result?.config || {};
+   }
+   
+   // Merge config with command line args (cli args take precedence)
+   return { ...config, ...argv };
+ };
+ ```
+ 
+ ## Parser Configuration
+ 
+ The CLI customizes the Yargs parser for optimal behavior:
+ 
+ ```typescript
+ // Configure yargs parser behavior
+ yargs
+   .parserConfiguration({
+     'camel-case-expansion': true,
+     'short-option-groups': true,
+     'strip-aliased': true,
+     'strip-dashed': true,
+     'halt-at-non-option': false,
+     'unknown-options-as-args': false
+   });
+ ```
+ 
+ ## Best Practices Implementation
+ 
+ The CLI follows Yargs best practices:
+ 
+ 1. **Consistent Command Structure**: Uses consistent verb-noun pattern for commands
+ 2. **Grouped Options**: Organizes related options into logical groups
+ 3. **Sensible Defaults**: Provides reasonable defaults for all options
+ 4. **Rich Documentation**: Includes detailed descriptions for all commands and options
+ 5. **Progressive Complexity**: Exposes basic functionality by default, with advanced options available when needed
+ 6. **Validation and Feedback**: Validates input early and provides clear error messages
+ 7. **Type Safety**: Leverages TypeScript for type-safe command definitions
+ 
+ ## Integration with CLI Components
+ 
+ The CLI integrates Yargs with other CLI components:
+ 
+ ```typescript
+ // Integration with CLI progress bars
+ import cliProgress from 'cli-progress';
+ 
+ const tagHandler = async (argv: Arguments<TagCommandOptions>) => {
+   // Calculate number of files to process
+   const files = await getFilesToProcess(argv.paths);
+   
+   // Create progress bar
+   const progressBar = new cliProgress.SingleBar({
+     format: 'Processing: [{bar}] {percentage}% | {value}/{total} files | ETA: {eta}s',
+     barCompleteChar: '=',
+     barIncompleteChar: ' '
+   });
+   
+   progressBar.start(files.length, 0);
+   
+   // Process files with progress updates
+   for (const file of files) {
+     await processFile(file, argv);
+     progressBar.increment();
+   }
+   
+   progressBar.stop();
+ };
+ ```
+ 
+ The CLI architecture with Yargs is designed to be maintainable, extensible, and user-friendly, providing a professional command-line experience for Obsidian Magic users. 
```

---

Now let's create an enhanced CLI overview document that references all our newly created files:

---

```diff
  - Intelligent model selection and fallback mechanisms
  - Comprehensive benchmarking capabilities
+ - Sophisticated workflow orchestration
+ - Rich command-line interface with Yargs integration
  
  ## Architecture
  - **tokenizers**: Accurate token counting for OpenAI models
  - **zod**: Runtime validation of configurations and API responses
+ - **inquirer**: Interactive command-line prompts for guided workflows
+ - **cosmiconfig**: Configuration discovery and loading from multiple sources
+ - **fs-extra**: Extended file system operations for robust file handling
+ 
+ ## Command Structure
+ 
+ The CLI implements a hierarchical command structure with nested subcommands:
+ 
+ ```bash
+ # Main command groups
+ tag-conversations tag      # Process and tag conversations
+ tag-conversations test     # Run tests and benchmarks
+ tag-conversations config   # Manage configuration
+ tag-conversations stats    # View statistics and reports
+ tag-conversations taxonomy # Manage taxonomy
+ ```
+ 
+ Each command group contains specialized subcommands for specific operations:
+ 
+ ```bash
+ # Example of config subcommands
+ tag-conversations config get [key]        # View configuration values
+ tag-conversations config set <key> <value> # Set configuration values
+ tag-conversations config import <file>     # Import configuration from file
+ tag-conversations config export --format=json # Export configuration to file
+ ```
+ 
+ For a complete reference of all commands and their options, see the [Command Structure & Options](./command-structure.md) documentation.
  
  ## Usage Examples
  # Force reprocessing of all files
  tag-conversations tag ./conversations/ --force
+ 
+ # Limit processing cost
+ tag-conversations tag ./conversations/ --max-cost=5.00
+ 
+ # Use a specific model
+ tag-conversations tag ./conversations/ --model=gpt-4
+ 
+ # Run a benchmark
+ tag-conversations test --benchmark --models=gpt-3.5-turbo,gpt-4
  ```
  
- ## Detailed Features
+ ## Workflow Orchestration
+ 
+ The CLI provides sophisticated workflow orchestration capabilities:
+ 
+ - Multiple processing modes (auto, interactive, differential)
+ - Concurrent processing with adaptive throttling
+ - Priority-based queuing system
+ - Resumable processing sessions
+ - Checkpoint system for fail-safe operation
+ 
+ For more details, see the [Workflow Orchestration](./workflow-orchestration.md) documentation.
+ 
+ ## Cost Management
+ 
+ Cost management is a core feature of the CLI:
+ 
+ - Precise token counting and cost estimation
+ - Real-time usage tracking during processing
+ - Budget controls with configurable thresholds
+ - Intelligent model selection based on task requirements
+ - Token optimization strategies for cost reduction
+ 
+ For more details, see the [Cost Management](./cost-management.md) documentation.
+ 
+ ## Benchmarking System
+ 
+ The CLI includes a comprehensive benchmarking system:
+ 
+ - Performance evaluation across different models
+ - Accuracy metrics for classification quality
+ - Cost-efficiency analysis
+ - Detailed reporting with visualizations
+ - Parameter optimization tools
+ 
+ For more details, see the [Benchmarking Capabilities](./benchmarking.md) documentation.
+ 
+ ## Yargs Integration
+ 
+ The CLI is built with Yargs for a professional command-line experience:
+ 
+ - Type-safe command and option definitions
+ - Rich help documentation and usage examples
+ - Command middleware for cross-cutting concerns
+ - Advanced features like auto-completion and validation
+ - Interactive features with inquirer integration
+ 
+ For more details on the implementation, see the [Yargs Implementation](./yargs-implementation.md) documentation.
+ 
+ ## Configuration Management
+ 
+ The CLI provides comprehensive configuration management:
+ 
+ - Environment variables with dotenv support
+ - Configuration files using cosmiconfig
+ - CLI options override configuration
+ - Configuration profiles for different workflows
+ - Import/export functionality
+ 
+ ```bash
+ # Using environment variables
+ OPENAI_API_KEY=your-key tag-conversations tag ./conversations/
+ 
+ # Using configuration file
+ tag-conversations --config=./my-config.json tag ./conversations/
+ 
+ # Creating a configuration profile
+ tag-conversations config create-profile fast-tagging --model=gpt-3.5-turbo --concurrency=5
+ ```
+ 
+ ## Interactive Features
+ 
+ The CLI includes interactive features for a guided experience:
+ 
+ - Model selection with cost estimates
+ - Interactive tagging review and approval
+ - Tag editing and refinement
+ - Progress visualization with spinners and progress bars
+ - Rich terminal output with color-coding and formatting
+ 
+ ## Installation
+ 
+ The CLI can be installed globally:
+ 
+ ```bash
+ # Using npm
+ npm install -g @obsidian-magic/cli
+ 
+ # Using yarn
+ yarn global add @obsidian-magic/cli
+ 
+ # Using pnpm
+ pnpm add -g @obsidian-magic/cli
+ ```
+ 
+ Or run directly using npx:
+ 
+ ```bash
+ npx @obsidian-magic/cli tag ./conversations/
+ ```
+ 
+ ## Related Documentation
  
  - [Command Structure & Options](./command-structure.md)
  - [Workflow Orchestration](./workflow-orchestration.md)
  - [Cost Management](./cost-management.md)
  - [Benchmarking Capabilities](./benchmarking.md)
+ - [Yargs Implementation](./yargs-implementation.md)
+ - [Error Handling Strategies](./error-handling.md)
+ - [Configuration Reference](./configuration-reference.md)
+ - [Interactive UI Features](./interactive-ui.md)
  
  ## Related Components
```

---

Now let's create two additional documents referenced in the overview:

---

```diff
- 
+ # Error Handling Strategies
+ 
+ The Obsidian Magic CLI implements a robust error handling system to ensure reliability, graceful failure recovery, and clear user feedback.
+ 
+ ## Error Handling Architecture
+ 
+ The CLI utilizes a multi-layered error handling approach:
+ 
+ ### Error Categories
+ 
+ Errors are categorized into several distinct types:
+ 
+ 1. **User Input Errors**: Invalid command-line arguments or configuration
+ 2. **System Errors**: File system, network, or resource issues
+ 3. **API Errors**: OpenAI API failures, rate limits, or authentication issues
+ 4. **Processing Errors**: File parsing, token counting, or tag application failures
+ 5. **Validation Errors**: Invalid data structures or unexpected response formats
+ 
+ ### Error Hierarchy
+ 
+ The CLI implements a typed error hierarchy:
+ 
+ ```typescript
+ // Base error class
+ class CliError extends Error {
+   code: string;
+   recoverable: boolean;
+   
+   constructor(message: string, code: string, recoverable = false) {
+     super(message);
+     this.name = this.constructor.name;
+     this.code = code;
+     this.recoverable = recoverable;
+   }
+ }
+ 
+ // Specific error types
+ class UserInputError extends CliError {
+   constructor(message: string, code = 'INVALID_INPUT') {
+     super(message, code, true);
+   }
+ }
+ 
+ class ApiError extends CliError {
+   statusCode?: number;
+   retryAfter?: number;
+   
+   constructor(message: string, code = 'API_ERROR', statusCode?: number, retryAfter?: number) {
+     super(message, code, statusCode ? statusCode < 500 : false);
+     this.statusCode = statusCode;
+     this.retryAfter = retryAfter;
+   }
+ }
+ 
+ // Additional error types...
+ ```
+ 
+ ## Command-Line Validation
+ 
+ The CLI performs validation at multiple levels:
+ 
+ ### Argument Validation
+ 
+ Yargs provides the first level of validation:
+ 
+ ```typescript
+ yargs
+   .option('concurrency', {
+     type: 'number',
+     describe: 'Number of parallel operations',
+     default: 3,
+     check: (value) => {
+       if (value < 1) {
+         throw new UserInputError('Concurrency must be at least 1');
+       }
+       return true;
+     }
+   })
+   .option('max-cost', {
+     type: 'number',
+     describe: 'Maximum budget for this run',
+     check: (value) => {
+       if (value <= 0) {
+         throw new UserInputError('Max cost must be greater than 0');
+       }
+       return true;
+     }
+   });
+ ```
+ 
+ ### Command Middleware Validation
+ 
+ Additional validation occurs in command middleware:
+ 
+ ```typescript
+ const validateApiCredentials = (argv: Arguments) => {
+   const apiKey = argv.apiKey || process.env.OPENAI_API_KEY;
+   
+   if (!apiKey) {
+     throw new UserInputError(
+       'OpenAI API key is required. Provide it via --api-key option or OPENAI_API_KEY environment variable',
+       'MISSING_API_KEY'
+     );
+   }
+   
+   return argv;
+ };
+ ```
+ 
+ ## API Error Handling
+ 
+ The CLI implements sophisticated API error handling:
+ 
+ ### Rate Limiting
+ 
+ ```typescript
+ const apiCallWithRetry = async <T>(
+   fn: () => Promise<T>,
+   options: RetryOptions = {}
+ ): Promise<T> => {
+   const {
+     maxRetries = 3,
+     initialDelay = 1000,
+     maxDelay = 60000,
+     factor = 2,
+   } = options;
+   
+   let attempt = 0;
+   
+   while (true) {
+     try {
+       return await fn();
+     } catch (error) {
+       attempt++;
+       
+       if (attempt > maxRetries) {
+         throw error;
+       }
+       
+       if (error instanceof ApiError && error.statusCode === 429) {
+         // Use retryAfter from API if available, otherwise use exponential backoff
+         const delay = error.retryAfter
+           ? error.retryAfter * 1000
+           : Math.min(initialDelay * Math.pow(factor, attempt - 1), maxDelay);
+         
+         logWarning(`Rate limited. Retrying in ${delay / 1000} seconds...`);
+         await sleep(delay);
+       } else if (isTransientError(error)) {
+         // Handle other transient errors
+         const delay = Math.min(initialDelay * Math.pow(factor, attempt - 1), maxDelay);
+         logWarning(`Transient error. Retrying in ${delay / 1000} seconds...`);
+         await sleep(delay);
+       } else {
+         // Non-recoverable error
+         throw error;
+       }
+     }
+   }
+ };
+ ```
+ 
+ ### Error Classification
+ 
+ The CLI classifies API errors for appropriate handling:
+ 
+ ```typescript
+ const isTransientError = (error: any): boolean => {
+   if (error instanceof ApiError) {
+     // 5xx errors, network timeouts
+     return (
+       error.statusCode >= 500 ||
+       error.code === 'ETIMEDOUT' ||
+       error.code === 'ECONNRESET'
+     );
+   }
+   
+   // Network-related errors
+   return (
+     error.code === 'ENOTFOUND' ||
+     error.code === 'EAI_AGAIN' ||
+     error.message.includes('ECONNREFUSED')
+   );
+ };
+ ```
+ 
+ ## File Processing Errors
+ 
+ The CLI handles file processing errors robustly:
+ 
+ ### Safe File Operations
+ 
+ ```typescript
+ const safelyProcessFile = async (
+   filePath: string,
+   options: ProcessOptions
+ ): Promise<ProcessResult> => {
+   try {
+     // Verify file exists
+     if (!fs.existsSync(filePath)) {
+       throw new FileSystemError(`File not found: ${filePath}`, 'FILE_NOT_FOUND');
+     }
+     
+     // Check permissions
+     try {
+       await fs.access(filePath, fs.constants.R_OK | fs.constants.W_OK);
+     } catch (e) {
+       throw new FileSystemError(
+         `Insufficient permissions for file: ${filePath}`,
+         'INSUFFICIENT_PERMISSIONS'
+       );
+     }
+     
+     // Backup file before processing if requested
+     if (options.backup) {
+       const backupPath = `${filePath}.backup`;
+       await fs.copyFile(filePath, backupPath);
+     }
+     
+     // Process file with structured error handling
+     return await processFile(filePath, options);
+   } catch (error) {
+     // Transform and enhance error
+     if (error instanceof CliError) {
+       // Add context to existing error
+       error.message = `Error processing ${filePath}: ${error.message}`;
+       throw error;
+     } else {
+       // Convert unknown error to FileProcessingError
+       throw new FileProcessingError(
+         `Error processing ${filePath}: ${error.message || 'Unknown error'}`,
+         'FILE_PROCESSING_ERROR'
+       );
+     }
+   }
+ };
+ ```
+ 
+ ### Batch Processing Error Handling
+ 
+ The CLI gracefully handles errors during batch processing:
+ 
+ ```typescript
+ const processBatch = async (
+   files: string[],
+   options: ProcessOptions
+ ): Promise<BatchResult> => {
+   const results: ProcessResult[] = [];
+   const errors: ProcessError[] = [];
+   
+   for (const file of files) {
+     try {
+       const result = await safelyProcessFile(file, options);
+       results.push(result);
+     } catch (error) {
+       // Record error and continue with other files
+       errors.push({
+         file,
+         error: error instanceof CliError ? error : new CliError(error.message, 'UNKNOWN_ERROR'),
+       });
+       
+       if (options.failFast) {
+         break;
+       }
+     }
+   }
+   
+   return {
+     results,
+     errors,
+     success: results.length,
+     failed: errors.length,
+     total: files.length,
+   };
+ };
+ ```
+ 
+ ## Error Reporting
+ 
+ The CLI provides comprehensive error reporting:
+ 
+ ### User-Friendly Output
+ 
+ ```typescript
+ const handleError = (error: unknown): never => {
+   if (error instanceof UserInputError) {
+     // Format user input errors clearly
+     console.error(chalk.red('Error:'), error.message);
+     console.error(chalk.yellow('Tip:'), 'Use --help to see valid options and usage');
+   } else if (error instanceof ApiError) {
+     // Format API errors with relevant details
+     console.error(chalk.red('API Error:'), error.message);
+     if (error.statusCode === 401) {
+       console.error(chalk.yellow('Tip:'), 'Check your API key and authentication settings');
+     } else if (error.statusCode === 429) {
+       console.error(chalk.yellow('Tip:'), 'You\'ve hit rate limits. Try again later or reduce concurrency');
+     }
+   } else if (error instanceof CliError) {
+     // Format known CLI errors
+     console.error(chalk.red(`${error.name}:`), error.message);
+     if (error.recoverable) {
+       console.error(chalk.yellow('Tip:'), 'This error may be recoverable. See error details above');
+     }
+   } else {
+     // Format unknown errors
+     console.error(chalk.red('Unexpected Error:'), error instanceof Error ? error.message : String(error));
+   }
+   
+   // Exit with appropriate code
+   process.exit(1);
+ };
+ ```
+ 
+ ### Detailed Logging
+ 
+ ```typescript
+ const logError = (error: Error | string, context?: Record<string, any>): void => {
+   const errorObj = error instanceof Error ? error : new Error(error);
+   
+   if (logger) {
+     logger.error({
+       msg: errorObj.message,
+       error: {
+         name: errorObj.name,
+         stack: errorObj.stack,
+         ...(errorObj instanceof CliError ? { code: errorObj.code } : {}),
+       },
+       context,
+     });
+   } else {
+     // Fallback if logger not initialized
+     console.error('[ERROR]', errorObj.message);
+     if (context) {
+       console.error('Context:', context);
+     }
+   }
+ };
+ ```
+ 
+ ## Graceful Degradation
+ 
+ The CLI implements graceful degradation for better reliability:
+ 
+ ### Fallback Mechanisms
+ 
+ ```typescript
+ const getClassificationTags = async (
+   content: string,
+   options: ClassificationOptions
+ ): Promise<ClassificationResult> => {
+   try {
+     // Try primary model first
+     return await classifyWithModel(content, options.model, options);
+   } catch (error) {
+     if (error instanceof ApiError && options.fallbackModel) {
+       // Log the fallback
+       logWarning(
+         `Failed to classify with ${options.model}, falling back to ${options.fallbackModel}`
+       );
+       
+       // Try fallback model
+       return await classifyWithModel(content, options.fallbackModel, options);
+     }
+     
+     // Re-throw if no fallback or not an API error
+     throw error;
+   }
+ };
+ ```
+ 
+ ### Partial Results
+ 
+ The CLI gracefully handles partial results:
+ 
+ ```typescript
+ const summarizeBatchResults = (
+   batchResult: BatchResult,
+   options: ProcessOptions
+ ): void => {
+   console.log(chalk.bold('\nProcessing Summary:'));
+   console.log(`✅ Successfully processed: ${batchResult.success} files`);
+   
+   if (batchResult.failed > 0) {
+     console.log(`❌ Failed to process: ${batchResult.failed} files`);
+     
+     if (options.verbose) {
+       // List failed files with reasons
+       console.log(chalk.bold('\nFailed Files:'));
+       batchResult.errors.forEach(({ file, error }) => {
+         console.log(`- ${file}: ${error.message}`);
+       });
+     }
+     
+     // Offer retry option if appropriate
+     if (options.interactive && batchResult.failed > 0) {
+       inquirer
+         .prompt([
+           {
+             type: 'confirm',
+             name: 'retry',
+             message: 'Would you like to retry failed files?',
+             default: false,
+           },
+         ])
+         .then(async ({ retry }) => {
+           if (retry) {
+             const filesToRetry = batchResult.errors.map((e) => e.file);
+             console.log(`Retrying ${filesToRetry.length} files...`);
+             await processBatch(filesToRetry, options);
+           }
+         });
+     }
+   }
+ };
+ ```
+ 
+ ## Error Prevention
+ 
+ The CLI implements strategies to prevent errors:
+ 
+ ### Preflight Checks
+ 
+ ```typescript
+ const runPreflightChecks = async (
+   options: ProcessOptions
+ ): Promise<PreflightResult> => {
+   const checks: PreflightCheck[] = [];
+   
+   // Check API credentials
+   checks.push({
+     name: 'API Credentials',
+     run: async () => {
+       const apiKey = options.apiKey || process.env.OPENAI_API_KEY;
+       if (!apiKey) {
+         return {
+           success: false,
+           message: 'OpenAI API key is missing',
+         };
+       }
+       
+       try {
+         // Verify API key with a minimal API call
+         await verifyApiKey(apiKey);
+         return { success: true };
+       } catch (error) {
+         return {
+           success: false,
+           message: `API key verification failed: ${error.message}`,
+         };
+       }
+     },
+   });
+   
+   // Check file access
+   if (options.paths.length > 0) {
+     checks.push({
+       name: 'File Access',
+       run: async () => {
+         const inaccessibleFiles = [];
+         
+         for (const path of options.paths) {
+           try {
+             const stats = await fs.stat(path);
+             if (stats.isDirectory()) {
+               // Check if directory is readable
+               await fs.access(path, fs.constants.R_OK);
+             } else {
+               // Check if file is readable and writable
+               await fs.access(path, fs.constants.R_OK | fs.constants.W_OK);
+             }
+           } catch (error) {
+             inaccessibleFiles.push(`${path} (${error.code})`);
+           }
+         }
+         
+         if (inaccessibleFiles.length > 0) {
+           return {
+             success: false,
+             message: `Cannot access some files: ${inaccessibleFiles.join(', ')}`,
+           };
+         }
+         
+         return { success: true };
+       },
+     });
+   }
+   
+   // Execute checks
+   const results = await Promise.all(checks.map(async (check) => {
+     try {
+       const result = await check.run();
+       return { ...check, ...result };
+     } catch (error) {
+       return {
+         ...check,
+         success: false,
+         message: `Check failed: ${error.message}`,
+       };
+     }
+   }));
+   
+   const allPassed = results.every((r) => r.success);
+   
+   return {
+     passed: allPassed,
+     checks: results,
+   };
+ };
+ ```
+ 
+ ## Debugging Support
+ 
+ The CLI includes rich debugging support:
+ 
+ ### Debug Mode
+ 
+ ```typescript
+ const enableDebugMode = (argv: Arguments): void => {
+   if (argv.debug) {
+     // Set environment variable
+     process.env.DEBUG = 'tag-conversations:*';
+     
+     // Configure detailed error stack traces
+     Error.stackTraceLimit = Infinity;
+     
+     // Setup debug logging
+     configureLogger('debug', true);
+     
+     logDebug('Debug mode enabled');
+     logDebug('Command arguments:', argv);
+   }
+ };
+ ```
+ 
+ ### State Dumps
+ 
+ ```typescript
+ const dumpStateForDebugging = (
+   state: ProcessingState,
+   error: Error
+ ): void => {
+   if (!process.env.DEBUG) return;
+   
+   const timestamp = new Date().toISOString().replace(/:/g, '-');
+   const debugDir = path.join(os.tmpdir(), 'tag-conversations-debug');
+   
+   try {
+     fs.mkdirSync(debugDir, { recursive: true });
+     
+     const debugFile = path.join(debugDir, `error-state-${timestamp}.json`);
+     
+     // Sanitize state to remove sensitive information
+     const sanitizedState = sanitizeStateForDump(state);
+     
+     // Add error details
+     const debugData = {
+       error: {
+         name: error.name,
+         message: error.message,
+         stack: error.stack,
+         ...(error instanceof CliError ? { code: error.code } : {}),
+       },
+       state: sanitizedState,
+       environment: {
+         nodeVersion: process.version,
+         platform: process.platform,
+         arch: process.arch,
+       },
+     };
+     
+     fs.writeFileSync(debugFile, JSON.stringify(debugData, null, 2));
+     logDebug(`Debug state dumped to ${debugFile}`);
+   } catch (e) {
+     logError('Failed to dump debug state', { error: e });
+   }
+ };
+ ```
+ 
+ ## Error Recovery
+ 
+ The CLI implements recovery mechanisms for interrupted operations:
+ 
+ ### Session Persistence
+ 
+ ```typescript
+ const saveSessionState = async (
+   sessionId: string,
+   state: SessionState
+ ): Promise<void> => {
+   const sessionDir = path.join(os.homedir(), '.tag-conversations', 'sessions');
+   await fs.mkdir(sessionDir, { recursive: true });
+   
+   const sessionFile = path.join(sessionDir, `${sessionId}.json`);
+   await fs.writeFile(sessionFile, JSON.stringify(state, null, 2));
+ };
+ 
+ const loadSessionState = async (
+   sessionId: string
+ ): Promise<SessionState | null> => {
+   const sessionFile = path.join(
+     os.homedir(),
+     '.tag-conversations',
+     'sessions',
+     `${sessionId}.json`
+   );
+   
+   try {
+     const data = await fs.readFile(sessionFile, 'utf8');
+     return JSON.parse(data) as SessionState;
+   } catch (error) {
+     if (error.code === 'ENOENT') {
+       return null; // Session doesn't exist
+     }
+     throw error;
+   }
+ };
+ 
+ const resumeSession = async (
+   sessionId: string,
+   options: ProcessOptions
+ ): Promise<void> => {
+   const state = await loadSessionState(sessionId);
+   
+   if (!state) {
+     throw new UserInputError(`Session not found: ${sessionId}`);
+   }
+   
+   // Restore queue state
+   const remainingFiles = state.queue.filter(
+     (item) => item.status === 'pending' || item.status === 'failed'
+   );
+   
+   if (remainingFiles.length === 0) {
+     console.log('No remaining files to process in this session.');
+     return;
+   }
+   
+   console.log(`Resuming session with ${remainingFiles.length} remaining files...`);
+   
+   // Process remaining files
+   await processBatch(
+     remainingFiles.map((item) => item.file),
+     {
+       ...options,
+       sessionId,
+     }
+   );
+ };
+ ```
+ 
+ ## Exit Handling
+ 
+ The CLI implements clean shutdown handling:
+ 
+ ```typescript
+ const setupExitHandlers = (cleanup: () => Promise<void>): void => {
+   let shuttingDown = false;
+   
+   const handleExit = async (signal: string): Promise<never> => {
+     if (shuttingDown) {
+       process.exit(1);
+     }
+     
+     shuttingDown = true;
+     console.log(`\n${signal} received. Cleaning up...`);
+     
+     try {
+       await cleanup();
+       console.log('Cleanup completed.');
+       process.exit(0);
+     } catch (error) {
+       console.error('Error during cleanup:', error);
+       process.exit(1);
+     }
+   };
+   
+   // Handle termination signals
+   process.on('SIGINT', () => handleExit('SIGINT'));
+   process.on('SIGTERM', () => handleExit('SIGTERM'));
+   
+   // Handle uncaught exceptions
+   process.on('uncaughtException', (error) => {
+     console.error('Uncaught exception:', error);
+     handleExit('UNCAUGHT EXCEPTION');
+   });
+   
+   // Handle unhandled promise rejections
+   process.on('unhandledRejection', (reason) => {
+     console.error('Unhandled promise rejection:', reason);
+     handleExit('UNHANDLED REJECTION');
+   });
+ };
+ ```
+ 
+ ## Best Practices
+ 
+ The CLI follows these error handling best practices:
+ 
+ 1. **Categorize Errors**: Group errors into meaningful categories
+ 2. **Specific Error Types**: Create specific error subclasses for different scenarios
+ 3. **Contextual Information**: Include context in error messages
+ 4. **User-Friendly Messages**: Present clear, actionable error messages
+ 5. **Recovery Options**: Provide recovery mechanisms when possible
+ 6. **Graceful Degradation**: Implement fallbacks for key functionality
+ 7. **Detailed Logging**: Log comprehensive error information for debugging
+ 8. **Clean Exit**: Handle exit signals properly and clean up resources
+ 9. **Preflight Checks**: Verify conditions before processing to prevent errors
+ 10. **Consistent Error Handling**: Apply consistent error handling patterns throughout the code 
```

---

```diff
- 
+ # Interactive UI Features
+ 
+ The Obsidian Magic CLI implements a rich interactive user interface for an engaging and intuitive command-line experience.
+ 
+ ## Terminal UI Components
+ 
+ The CLI leverages several high-quality libraries to create an interactive terminal UI:
+ 
+ ### Libraries and Components
+ 
+ - **inquirer**: Interactive prompts and menus
+ - **ora**: Elegant terminal spinners
+ - **chalk**: Terminal text styling and coloring
+ - **cli-progress**: Customizable progress bars
+ - **boxen**: Information boxes for statistics and summaries
+ - **figures**: Unicode symbols for better visual indicators
+ - **gradient-string**: Colorful gradient text for emphasis
+ 
+ ## Interactive Workflows
+ 
+ The CLI provides an interactive workflow mode:
+ 
+ ### Mode Selection
+ 
+ ```bash
+ # Enable interactive mode
+ tag-conversations tag ./convos/ --mode=interactive
+ ```
+ 
+ ### Interactive Processing Flow
+ 
+ The interactive mode follows a guided workflow:
+ 
+ 1. **Initial File Scan**: Displays progress during file discovery
+ 2. **Pre-processing Summary**: Shows token counts and cost estimates
+ 3. **Model Selection**: Interactive menu for model choice with cost information
+ 4. **Per-file Confirmation**: Prompt for each file with preview information
+ 5. **Tag Review**: Interactive review and editing of generated tags
+ 6. **Batch Configuration**: Adaptive options based on current batch
+ 
+ ```typescript
+ // Example of interactive file confirmation
+ const processFilesInteractively = async (
+   files: string[],
+   options: ProcessOptions
+ ): Promise<ProcessResult[]> => {
+   const results: ProcessResult[] = [];
+   
+   for (const file of files) {
+     // Display file information
+     const fileInfo = await getFileInfo(file);
+     
+     console.log(boxen(formatFileInfo(fileInfo), {
+       padding: 1,
+       margin: 1,
+       borderColor: 'blue',
+       title: path.basename(file),
+       titleAlignment: 'center'
+     }));
+     
+     // Prompt for action
+     const { action } = await inquirer.prompt([
+       {
+         type: 'list',
+         name: 'action',
+         message: 'What would you like to do with this file?',
+         choices: [
+           { name: 'Process file', value: 'process' },
+           { name: 'Skip file', value: 'skip' },
+           { name: 'Preview file content', value: 'preview' },
+           { name: 'View estimated tokens', value: 'tokens' }
+         ]
+       }
+     ]);
+     
+     if (action === 'skip') {
+       continue;
+     } else if (action === 'preview') {
+       await previewFile(file);
+       // Ask again after preview
+       const { nextAction } = await inquirer.prompt([
+         {
+           type: 'list',
+           name: 'nextAction',
+           message: 'Next action:',
+           choices: [
+             { name: 'Process file', value: 'process' },
+             { name: 'Skip file', value: 'skip' }
+           ]
+         }
+       ]);
+       
+       if (nextAction === 'skip') {
+         continue;
+       }
+     } else if (action === 'tokens') {
+       await showTokenEstimate(file, options.model);
+       // Continue to processing after showing tokens
+     }
+     
+     // Process file with spinner
+     const spinner = ora(`Processing ${path.basename(file)}...`).start();
+     
+     try {
+       const result = await processFile(file, options);
+       spinner.succeed(`Processed ${path.basename(file)}`);
+       
+       // Tag review and editing
+       const editedResult = await reviewTags(result);
+       results.push(editedResult);
+     } catch (error) {
+       spinner.fail(`Failed to process ${path.basename(file)}`);
+       console.error(chalk.red('Error:'), error.message);
+       
+       // Prompt for retry
+       const { retry } = await inquirer.prompt([
+         {
+           type: 'confirm',
+           name: 'retry',
+           message: 'Would you like to retry this file?',
+           default: true
+         }
+       ]);
+       
+       if (retry) {
+         // Decrement counter to retry this file
+         i--;
+       }
+     }
+   }
+   
+   return results;
+ };
+ ```
+ 
+ ## Tag Review and Editing
+ 
+ The CLI provides interactive tag review and editing:
+ 
+ ### Tag Editor
+ 
+ ```typescript
+ const reviewTags = async (
+   result: ProcessResult
+ ): Promise<ProcessResult> => {
+   console.log(chalk.bold('\nGenerated Tags:'));
+   
+   // Display tags with confidence scores
+   result.tags.forEach((tag, index) => {
+     const confidence = tag.confidence || 1.0;
+     const color = confidence > 0.8 ? 'green' : confidence > 0.5 ? 'yellow' : 'red';
+     
+     console.log(
+       `${index + 1}. ${chalk[color](tag.name)} ` +
+       `(${chalk.dim(`${(confidence * 100).toFixed(1)}% confidence`)})`
+     );
+   });
+   
+   // Prompt for tag editing
+   const { action } = await inquirer.prompt([
+     {
+       type: 'list',
+       name: 'action',
+       message: 'Would you like to edit these tags?',
+       choices: [
+         { name: 'Keep tags as is', value: 'keep' },
+         { name: 'Edit tags', value: 'edit' },
+         { name: 'Add new tag', value: 'add' },
+         { name: 'Remove tag', value: 'remove' }
+       ]
+     }
+   ]);
+   
+   // Handle different actions
+   if (action === 'keep') {
+     return result;
+   } else if (action === 'edit') {
+     return await editExistingTags(result);
+   } else if (action === 'add') {
+     return await addNewTag(result);
+   } else if (action === 'remove') {
+     return await removeTag(result);
+   }
+   
+   return result;
+ };
+ ```
+ 
+ ## Progress Visualization
+ 
+ The CLI provides rich progress visualization:
+ 
+ ### Progress Bars
+ 
+ ```typescript
+ const processBatchWithProgress = async (
+   files: string[],
+   options: ProcessOptions
+ ): Promise<BatchResult> => {
+   // Create multi-bar container
+   const multibar = new cliProgress.MultiBar(
+     {
+       clearOnComplete: false,
+       hideCursor: true,
+       format: '{bar} {percentage}% | {value}/{total} files | ETA: {eta_formatted}'
+     },
+     cliProgress.Presets.shades_grey
+   );
+   
+   // Main progress bar
+   const mainBar = multibar.create(files.length, 0, {
+     task: 'Processing'
+   });
+   
+   // Token usage bar (updates during processing)
+   const tokenBar = multibar.create(100, 0, {
+     task: 'Token usage'
+   });
+   
+   // Create processing queue with concurrency control
+   const results: ProcessResult[] = [];
+   const errors: ProcessError[] = [];
+   
+   const queue = new PQueue({ concurrency: options.concurrency });
+   
+   // Add tasks to queue
+   for (const file of files) {
+     queue.add(async () => {
+       try {
+         const result = await processFile(file, options);
+         results.push(result);
+         
+         // Update token usage in the second bar
+         const tokenPercentage = calculateTokenPercentage(result, options.maxTokens);
+         tokenBar.update(tokenPercentage);
+       } catch (error) {
+         errors.push({
+           file,
+           error: error instanceof CliError ? error : new CliError(error.message, 'UNKNOWN_ERROR')
+         });
+       } finally {
+         mainBar.increment();
+       }
+     });
+   }
+   
+   // Wait for all tasks to complete
+   await queue.onIdle();
+   multibar.stop();
+   
+   return {
+     results,
+     errors,
+     success: results.length,
+     failed: errors.length,
+     total: files.length
+   };
+ };
+ ```
+ 
+ ### Spinners
+ 
+ ```typescript
+ const verifyApiKeyWithSpinner = async (
+   apiKey: string
+ ): Promise<boolean> => {
+   const spinner = ora('Verifying API key...').start();
+   
+   try {
+     await verifyApiKey(apiKey);
+     spinner.succeed('API key verified successfully');
+     return true;
+   } catch (error) {
+     spinner.fail(`API key verification failed: ${error.message}`);
+     return false;
+   }
+ };
+ ```
+ 
+ ## Interactive Configuration
+ 
+ The CLI provides interactive configuration management:
+ 
+ ### Configuration Wizard
+ 
+ ```typescript
+ const runConfigWizard = async (): Promise<void> => {
+   console.log(chalk.bold('Configuration Wizard'));
+   console.log('Let\'s set up your Obsidian Magic CLI configuration.\n');
+   
+   // API key setup
+   const { apiKey } = await inquirer.prompt([
+     {
+       type: 'password',
+       name: 'apiKey',
+       message: 'Enter your OpenAI API key:',
+       validate: (input) => input.length > 0 ? true : 'API key is required'
+     }
+   ]);
+   
+   // Verify API key
+   const isValid = await verifyApiKeyWithSpinner(apiKey);
+   
+   if (!isValid) {
+     console.log(chalk.red('Invalid API key. Please try again.'));
+     return;
+   }
+   
+   // Default model selection
+   const { defaultModel } = await inquirer.prompt([
+     {
+       type: 'list',
+       name: 'defaultModel',
+       message: 'Select your default model:',
+       choices: [
+         { name: 'GPT-3.5 Turbo (Faster, lower cost)', value: 'gpt-3.5-turbo' },
+         { name: 'GPT-4 (Higher accuracy, higher cost)', value: 'gpt-4' },
+         { name: 'GPT-4 Turbo (Best balance of speed/accuracy)', value: 'gpt-4-turbo-preview' }
+       ]
+     }
+   ]);
+   
+   // Default behavior preferences
+   const { defaultMode, maxConcurrency, backupFiles } = await inquirer.prompt([
+     {
+       type: 'list',
+       name: 'defaultMode',
+       message: 'Select default processing mode:',
+       choices: [
+         { name: 'Auto (Process all files automatically)', value: 'auto' },
+         { name: 'Interactive (Confirm each file)', value: 'interactive' },
+         { name: 'Differential (Only process files missing tags)', value: 'differential' }
+       ]
+     },
+     {
+       type: 'number',
+       name: 'maxConcurrency',
+       message: 'Maximum concurrent operations:',
+       default: 3,
+       validate: (input) => input > 0 ? true : 'Must be greater than 0'
+     },
+     {
+       type: 'confirm',
+       name: 'backupFiles',
+       message: 'Create backups before modifying files?',
+       default: true
+     }
+   ]);
+   
+   // Save configuration
+   await saveConfig({
+     apiKey,
+     defaultModel,
+     defaultMode,
+     maxConcurrency,
+     backupFiles
+   });
+   
+   console.log(chalk.green('\nConfiguration saved successfully!'));
+   console.log('You can modify these settings anytime using:');
+   console.log(chalk.cyan('tag-conversations config set <key> <value>'));
+ };
+ ```
+ 
+ ## Rich Data Display
+ 
+ The CLI implements visually appealing data displays:
+ 
+ ### Statistics Display
+ 
+ ```typescript
+ const displayProcessingSummary = (
+   batchResult: BatchResult,
+   options: ProcessOptions
+ ): void => {
+   // Calculate statistics
+   const totalTokens = batchResult.results.reduce(
+     (sum, result) => sum + (result.tokenUsage?.total || 0),
+     0
+   );
+   
+   const totalCost = batchResult.results.reduce(
+     (sum, result) => sum + (result.cost || 0),
+     0
+   );
+   
+   const avgTokensPerFile = totalTokens / batchResult.results.length || 0;
+   
+   // Generate summary box
+   const summary = [
+     `${chalk.bold('Processing Summary')}`,
+     ``,
+     `${chalk.green('✓')} Files Processed: ${batchResult.success} of ${batchResult.total}`,
+     `${chalk.red('✗')} Files Failed: ${batchResult.failed}`,
+     ``,
+     `${chalk.bold('Resource Usage')}`,
+     `${figures.triangleRight} Total Tokens: ${totalTokens.toLocaleString()}`,
+     `${figures.triangleRight} Avg. Tokens/File: ${avgTokensPerFile.toFixed(1)}`,
+     `${figures.triangleRight} Total Cost: $${totalCost.toFixed(4)}`,
+     ``,
+     `${chalk.bold('Model')}`,
+     `${figures.triangleRight} ${options.model}`
+   ];
+   
+   console.log(boxen(summary.join('\n'), {
+     padding: 1,
+     margin: 1,
+     borderColor: 'green',
+     title: 'Tagging Complete',
+     titleAlignment: 'center'
+   }));
+   
+   // Display tag distribution if requested
+   if (options.showStats) {
+     displayTagDistribution(batchResult.results);
+   }
+ };
+ ```
+ 
+ ### Color-Coded Information
+ 
+ ```typescript
+ const formatModelComparison = (
+   models: ModelComparisonResult[]
+ ): string => {
+   let output = '';
+   
+   models.forEach((model) => {
+     // Color-code based on performance
+     const nameColor = model.recommended ? chalk.green : chalk.white;
+     const costColor = model.costRank === 1 ? chalk.green : chalk.yellow;
+     const accuracyColor = model.accuracyRank === 1 ? chalk.green : chalk.yellow;
+     
+     output += `${nameColor.bold(model.name)}\n`;
+     output += `  Accuracy: ${accuracyColor(`${(model.accuracy * 100).toFixed(1)}%`)}\n`;
+     output += `  Cost: ${costColor(`$${model.costPer100Files.toFixed(2)} per 100 files`)}\n`;
+     output += `  Speed: ${model.avgProcessingTime.toFixed(2)}s per file\n`;
+     
+     if (model.recommended) {
+       output += `  ${chalk.green.bold('✓ Recommended')}\n`;
+     }
+     
+     output += '\n';
+   });
+   
+   return output;
+ };
+ ```
+ 
+ ## Customizable UI Experience
+ 
+ The CLI allows customization of the UI experience:
+ 
+ ### Output Formats
+ 
+ ```bash
+ # Pretty format (default)
+ tag-conversations tag ./convos/ --format=pretty
+ 
+ # JSON output (for programmatic consumption)
+ tag-conversations tag ./convos/ --format=json
+ 
+ # Minimal output (for scripting)
+ tag-conversations tag ./convos/ --format=minimal
+ 
+ # Silent mode (no output except errors)
+ tag-conversations tag ./convos/ --format=silent
+ ```
+ 
+ ### Verbosity Levels
+ 
+ ```bash
+ # Standard output
+ tag-conversations tag ./convos/
+ 
+ # Verbose output
+ tag-conversations tag ./convos/ --verbose
+ 
+ # Debug output
+ tag-conversations tag ./convos/ --debug
+ ```
+ 
+ ## Keyboard Controls
+ 
+ The CLI implements keyboard shortcuts for interactive sessions:
+ 
+ ### Key Bindings
+ 
+ ```typescript
+ const configureKeyBindings = (
+   state: SessionState
+ ): void => {
+   process.stdin.setRawMode(true);
+   process.stdin.resume();
+   process.stdin.setEncoding('utf8');
+   
+   process.stdin.on('data', (key) => {
+     // Ctrl+C - Exit
+     if (key === '\u0003') {
+       handleExitRequest(state);
+       return;
+     }
+     
+     // Space - Pause/Resume
+     if (key === ' ') {
+       if (state.status === 'running') {
+         pauseProcessing(state);
+         console.log(chalk.yellow('Processing paused. Press space to resume.'));
+       } else if (state.status === 'paused') {
+         resumeProcessing(state);
+         console.log(chalk.green('Processing resumed.'));
+       }
+       return;
+     }
+     
+     // S - Show status
+     if (key.toLowerCase() === 's') {
+       displaySessionStatus(state);
+       return;
+     }
+     
+     // H - Show help
+     if (key.toLowerCase() === 'h') {
+       displayKeyboardShortcuts();
+       return;
+     }
+   });
+ };
+ 
+ const displayKeyboardShortcuts = (): void => {
+   console.log(boxen(
+     `${chalk.bold('Keyboard Shortcuts')}\n\n` +
+     `${chalk.bold('Space')} - Pause/Resume processing\n` +
+     `${chalk.bold('S')} - Show current status\n` +
+     `${chalk.bold('H')} - Show this help\n` +
+     `${chalk.bold('Ctrl+C')} - Exit (with confirmation)`,
+     {
+       padding: 1,
+       margin: 1,
+       borderColor: 'blue',
+       title: 'Help',
+       titleAlignment: 'center'
+     }
+   ));
+ };
+ ```
+ 
+ ## Discoverability Features
+ 
+ The CLI implements features to enhance discoverability:
+ 
+ ### Dynamic Help
+ 
+ ```typescript
+ const showContextualHelp = (
+   context: string,
+   options: HelpOptions = {}
+ ): void => {
+   let helpContent = '';
+   
+   switch (context) {
+     case 'token-optimization':
+       helpContent = formatTokenOptimizationHelp(options);
+       break;
+     case 'model-selection':
+       helpContent = formatModelSelectionHelp(options);
+       break;
+     case 'tag-editing':
+       helpContent = formatTagEditingHelp(options);
+       break;
+     default:
+       helpContent = formatGeneralHelp();
+       break;
+   }
+   
+   console.log(boxen(helpContent, {
+     padding: 1,
+     margin: 1,
+     borderColor: 'blue',
+     title: 'Help',
+     titleAlignment: 'center'
+   }));
+ };
+ ```
+ 
+ ### Tips and Suggestions
+ 
+ ```typescript
+ const showProTips = (
+   context: string,
+   usage: UsageStatistics
+ ): void => {
+   let tip = '';
+   
+   // Select tip based on context and usage patterns
+   if (context === 'cost-management' && usage.avgTokensPerFile > 2000) {
+     tip = `Pro Tip: You're using ${usage.avgTokensPerFile.toFixed(0)} tokens per file on average. ` +
+           `Try enabling token optimization with --optimize-tokens to reduce costs.`;
+   } else if (context === 'processing-speed' && usage.filesProcessed > 50) {
+     tip = `Pro Tip: For large batches like this (${usage.filesProcessed} files), ` +
+           `try increasing concurrency with --concurrency=5 to speed up processing.`;
+   } else if (context === 'tag-quality' && usage.avgTagsPerFile < 3) {
+     tip = `Pro Tip: Your files are receiving only ${usage.avgTagsPerFile.toFixed(1)} tags on average. ` +
+           `Consider using --model=gpt-4 for more comprehensive tagging.`;
+   } else {
+     // General tips
+     const tips = [
+       `Pro Tip: Use --dry-run to estimate costs before processing.`,
+       `Pro Tip: Create configuration profiles for different use cases with 'config create-profile'.`,
+       `Pro Tip: Press H during processing to see keyboard shortcuts.`,
+       `Pro Tip: Use --mode=differential to only process files missing tags.`
+     ];
+     
+     // Select random tip
+     tip = tips[Math.floor(Math.random() * tips.length)];
+   }
+   
+   console.log(chalk.blue(figures.info), chalk.italic(tip));
+ };
+ ```
+ 
+ ## Integration with System UI
+ 
+ The CLI integrates with system notifications for long-running operations:
+ 
+ ### Desktop Notifications
+ 
+ ```typescript
+ const sendNotification = async (
+   title: string,
+   message: string,
+   options: NotificationOptions = {}
+ ): Promise<void> => {
+   // Skip if notifications are disabled
+   if (config.get('disableNotifications')) return;
+   
+   try {
+     // Use node-notifier if available
+     const notifier = await import('node-notifier').catch(() => null);
+     
+     if (notifier) {
+       notifier.notify({
+         title,
+         message,
+         icon: options.icon || path.join(__dirname, '../assets/icon.png'),
+         sound: options.sound !== false,
+         wait: options.wait || false
+       });
+     }
+   } catch (error) {
+     // Silently fail if notifications aren't supported
+     logDebug('Failed to send notification', { error });
+   }
+ };
+ 
+ // Usage example
+ const notifyProcessingComplete = (
+   batchResult: BatchResult
+ ): void => {
+   sendNotification(
+     'Processing Complete',
+     `Successfully processed ${batchResult.success} files with ${batchResult.failed} failures.`,
+     { sound: true }
+   );
+ };
+ ```
+ 
+ The interactive UI features create an engaging and efficient command-line experience, balancing ease of use with powerful functionality for both beginners and advanced users. 
```

---

Let's also create a configuration reference document:

---

```diff
- 
+ # Configuration Reference
+ 
+ The Obsidian Magic CLI provides a comprehensive configuration system with multiple layers and flexible options for customization.
+ 
+ ## Configuration System Architecture
+ 
+ The CLI implements a layered configuration system with well-defined precedence:
+ 
+ ### Configuration Precedence
+ 
+ Configuration values are resolved in the following order (highest priority first):
+ 
+ 1. **Command-line Arguments**: Options provided directly in the command
+ 2. **Environment Variables**: Settings in the current environment
+ 3. **Project Configuration**: Local configuration in the current project
+ 4. **User Configuration**: User-specific settings in the home directory
+ 5. **Default Values**: Built-in defaults for all options
+ 
+ This multi-layered approach allows for flexibility while maintaining consistent behavior.
+ 
+ ## Configuration File Locations
+ 
+ The CLI searches for configuration in multiple locations:
+ 
+ ```
+ # Project-level configuration
+ ./tag-conversations.config.js
+ ./tag-conversations.config.json
+ ./tag-conversations.json
+ ./.tag-conversationsrc
+ 
+ # User-level configuration
+ ~/.tag-conversations/config.json
+ ~/.tag-conversationsrc
+ ~/.config/tag-conversations/config.json
+ 
+ # Environment-specific configuration
+ ./tag-conversations.${NODE_ENV}.json
+ ```
+ 
+ ## Configuration File Format
+ 
+ Configuration can be specified in JSON format:
+ 
+ ```json
+ {
+   "defaultModel": "gpt-3.5-turbo",
+   "maxCost": 5.0,
+   "concurrency": 3,
+   "backupFiles": true,
+   "api": {
+     "baseUrl": "https://api.openai.com/v1",
+     "timeout": 30000
+   },
+   "tagSettings": {
+     "minConfidence": 0.7,
+     "maxTags": 10,
+     "tagMode": "merge"
+   },
+   "processing": {
+     "defaultMode": "differential",
+     "skipExistingTags": true,
+     "includePatterns": ["**/*.md"],
+     "excludePatterns": ["**/node_modules/**", "**/archive/**"]
+   }
+ }
+ ```
+ 
+ Or in JavaScript format for more advanced configuration:
+ 
+ ```javascript
+ // tag-conversations.config.js
+ module.exports = {
+   defaultModel: process.env.NODE_ENV === 'production' ? 'gpt-4' : 'gpt-3.5-turbo',
+   maxCost: 5.0,
+   concurrency: require('os').cpus().length - 1, // Dynamic based on system
+   processing: {
+     defaultMode: 'differential',
+     excludePatterns: [
+       '**/node_modules/**',
+       '**/archive/**',
+       // Dynamic pattern based on date
+       `**/${new Date().getFullYear() - 1}/**` // Exclude last year's content
+     ]
+   },
+   // Function to determine tag mode based on file count
+   getTagMode: function(fileCount) {
+     return fileCount > 100 ? 'augment' : 'merge';
+   }
+ };
+ ```
+ 
+ ## Environment Variables
+ 
+ The CLI supports configuration through environment variables:
+ 
+ | Environment Variable | Description | Example |
+ |----------------------|-------------|---------|
+ | `OPENAI_API_KEY` | OpenAI API key | `OPENAI_API_KEY=sk-...` |
+ | `OPENAI_ORG_ID` | OpenAI organization ID | `OPENAI_ORG_ID=org-...` |
+ | `TAG_CONVERSATIONS_CONFIG` | Path to config file | `TAG_CONVERSATIONS_CONFIG=./custom-config.json` |
+ | `TAG_CONVERSATIONS_DEFAULT_MODEL` | Default model to use | `TAG_CONVERSATIONS_DEFAULT_MODEL=gpt-4` |
+ | `TAG_CONVERSATIONS_MAX_COST` | Maximum cost per run | `TAG_CONVERSATIONS_MAX_COST=10.0` |
+ | `TAG_CONVERSATIONS_CONCURRENCY` | Default concurrency | `TAG_CONVERSATIONS_CONCURRENCY=5` |
+ | `TAG_CONVERSATIONS_LOG_LEVEL` | Logging level | `TAG_CONVERSATIONS_LOG_LEVEL=debug` |
+ | `TAG_CONVERSATIONS_BACKUP` | Enable/disable backups | `TAG_CONVERSATIONS_BACKUP=true` |
+ | `TAG_CONVERSATIONS_API_TIMEOUT` | API timeout in ms | `TAG_CONVERSATIONS_API_TIMEOUT=60000` |
+ 
+ Environment variables can be loaded from a `.env` file in the current directory:
+ 
+ ```bash
+ # .env file
+ OPENAI_API_KEY=sk-your-api-key
+ TAG_CONVERSATIONS_DEFAULT_MODEL=gpt-4
+ TAG_CONVERSATIONS_MAX_COST=10.0
+ ```
+ 
+ ## Configuration Management Commands
+ 
+ The CLI provides commands for managing configuration:
+ 
+ ```bash
+ # View current configuration
+ tag-conversations config get
+ 
+ # View specific configuration value
+ tag-conversations config get defaultModel
+ 
+ # Set configuration value
+ tag-conversations config set defaultModel gpt-4
+ 
+ # Set nested configuration value
+ tag-conversations config set "api.timeout" 60000
+ 
+ # Reset configuration to defaults
+ tag-conversations config reset
+ 
+ # Generate config file with current settings
+ tag-conversations config init
+ 
+ # Import configuration from file
+ tag-conversations config import ./config.json
+ 
+ # Export configuration to file
+ tag-conversations config export --format=json
+ ```
+ 
+ ## Configuration Profiles
+ 
+ The CLI supports configuration profiles for different use cases:
+ 
+ ```bash
+ # Create a named profile
+ tag-conversations config create-profile fast-tagging --model=gpt-3.5-turbo --concurrency=5
+ 
+ # Use a profile
+ tag-conversations tag ./convos/ --profile=fast-tagging
+ 
+ # List available profiles
+ tag-conversations config list-profiles
+ 
+ # Delete a profile
+ tag-conversations config delete-profile fast-tagging
+ ```
+ 
+ Profiles are stored in `~/.tag-conversations/profiles/` and can be shared across projects.
+ 
+ ## Command-Line Configuration Options
+ 
+ All configuration options can be specified as command-line arguments:
+ 
+ ### Global Options
+ 
+ ```bash
+ # Specify configuration file
+ tag-conversations --config=./custom-config.json tag ./convos/
+ 
+ # Use configuration profile
+ tag-conversations --profile=fast-tagging tag ./convos/
+ 
+ # Override API key
+ tag-conversations --api-key=sk-your-api-key tag ./convos/
+ 
+ # Set log level
+ tag-conversations --log-level=debug tag ./convos/
+ 
+ # Load specific .env file
+ tag-conversations --env-file=./.env.production tag ./convos/
+ ```
+ 
+ ### Processing Options
+ 
+ ```bash
+ # Set processing mode
+ tag-conversations tag ./convos/ --mode=interactive
+ 
+ # Specify model
+ tag-conversations tag ./convos/ --model=gpt-4
+ 
+ # Set concurrency
+ tag-conversations tag ./convos/ --concurrency=5
+ 
+ # Set maximum cost
+ tag-conversations tag ./convos/ --max-cost=10.0
+ 
+ # Configure tag handling
+ tag-conversations tag ./convos/ --tag-mode=merge
+ 
+ # Control backup behavior
+ tag-conversations tag ./convos/ --backup=true
+ 
+ # Specify custom include/exclude patterns
+ tag-conversations tag ./convos/ --include="**/*.md" --exclude="**/archive/**"
+ ```
+ 
+ ## Validation and Type Safety
+ 
+ The CLI validates configuration against a schema:
+ 
+ ```typescript
+ // Configuration schema definition
+ const configSchema = z.object({
+   defaultModel: z.string().default('gpt-3.5-turbo'),
+   maxCost: z.number().positive().default(5.0),
+   concurrency: z.number().int().positive().default(3),
+   backupFiles: z.boolean().default(true),
+   api: z.object({
+     baseUrl: z.string().url().default('https://api.openai.com/v1'),
+     timeout: z.number().int().positive().default(30000)
+   }).default({}),
+   tagSettings: z.object({
+     minConfidence: z.number().min(0).max(1).default(0.7),
+     maxTags: z.number().int().positive().default(10),
+     tagMode: z.enum(['overwrite', 'merge', 'augment']).default('merge')
+   }).default({}),
+   processing: z.object({
+     defaultMode: z.enum(['auto', 'interactive', 'differential']).default('differential'),
+     skipExistingTags: z.boolean().default(true),
+     includePatterns: z.array(z.string()).default(['**/*.md']),
+     excludePatterns: z.array(z.string()).default(['**/node_modules/**', '**/archive/**'])
+   }).default({})
+ });
+ 
+ // Type definition for strongly typed configuration access
+ type ConfigSchema = z.infer<typeof configSchema>;
+ ```
+ 
+ ## Configuration API
+ 
+ The CLI provides a programmatic API for working with configuration:
+ 
+ ```typescript
+ import { getConfig, setConfig, resetConfig } from '@obsidian-magic/cli';
+ 
+ // Get full configuration
+ const config = getConfig();
+ console.log(`Using model: ${config.defaultModel}`);
+ 
+ // Get specific configuration value
+ const maxCost = getConfig('maxCost');
+ console.log(`Maximum cost: $${maxCost}`);
+ 
+ // Set configuration value
+ setConfig('defaultModel', 'gpt-4');
+ 
+ // Set nested configuration value
+ setConfig('api.timeout', 60000);
+ 
+ // Reset configuration
+ resetConfig();
+ ```
+ 
+ ## Default Configuration
+ 
+ The CLI includes sensible defaults for all configuration options:
+ 
+ ```javascript
+ // Default configuration values
+ const defaults = {
+   // Model settings
+   defaultModel: 'gpt-3.5-turbo',
+   fallbackModel: 'gpt-3.5-turbo',
+   
+   // Cost management
+   maxCost: 5.0,
+   onCostLimit: 'pause',
+   
+   // Processing settings
+   concurrency: 3,
+   backupFiles: true,
+   
+   // API settings
+   api: {
+     baseUrl: 'https://api.openai.com/v1',
+     timeout: 30000,
+     maxRetries: 3,
+     retryDelay: 1000
+   },
+   
+   // Tag settings
+   tagSettings: {
+     minConfidence: 0.7,
+     maxTags: 10,
+     tagMode: 'merge'
+   },
+   
+   // Processing settings
+   processing: {
+     defaultMode: 'differential',
+     skipExistingTags: true,
+     includePatterns: ['**/*.md'],
+     excludePatterns: ['**/node_modules/**', '**/archive/**']
+   },
+   
+   // UI settings
+   ui: {
+     showSpinners: true,
+     colorOutput: true,
+     progressBars: true,
+     verbosity: 'normal'
+   },
+   
+   // Output settings
+   output: {
+     format: 'pretty',
+     timestamps: false
+   },
+   
+   // System settings
+   system: {
+     tempDir: os.tmpdir(),
+     cacheDir: path.join(os.homedir(), '.tag-conversations', 'cache'),
+     logFile: path.join(os.homedir(), '.tag-conversations', 'logs', 'cli.log')
+   }
+ };
+ ```
+ 
+ ## Advanced Configuration Use Cases
+ 
+ ### Environment-specific Configuration
+ 
+ Create environment-specific configuration files:
+ 
+ ```bash
+ # Development configuration
+ tag-conversations.development.json
+ 
+ # Production configuration
+ tag-conversations.production.json
+ 
+ # Test configuration
+ tag-conversations.test.json
+ ```
+ 
+ Then specify the environment:
+ 
+ ```bash
+ # Use development configuration
+ NODE_ENV=development tag-conversations tag ./convos/
+ 
+ # Use production configuration
+ NODE_ENV=production tag-conversations tag ./convos/
+ ```
+ 
+ ### Dynamic Configuration
+ 
+ Use JavaScript configuration for dynamic settings:
+ 
+ ```javascript
+ // tag-conversations.config.js
+ module.exports = {
+   // Determine model based on file count
+   getModel: function(files) {
+     return files.length > 100 ? 'gpt-3.5-turbo' : 'gpt-4';
+   },
+   
+   // Determine concurrency based on system resources
+   getConcurrency: function() {
+     const cpus = require('os').cpus().length;
+     const memory = require('os').totalmem() / 1024 / 1024 / 1024; // GB
+     
+     // Adjust concurrency based on available resources
+     if (memory < 4) return 1; // Low memory system
+     if (memory < 8) return Math.min(2, cpus - 1); // Medium memory
+     return Math.min(5, cpus - 1); // High memory system
+   },
+   
+   // Customize API timeouts based on model
+   getApiTimeout: function(model) {
+     if (model.includes('gpt-4')) return 60000; // 60 seconds for GPT-4
+     return 30000; // 30 seconds for other models
+   }
+ };
+ ```
+ 
+ ### Per-directory Configuration
+ 
+ The CLI supports per-directory configuration, useful for repositories with different requirements:
+ 
+ ```
+ project/
+ ├── team1/
+ │   └── .tag-conversationsrc  # Team 1 specific configuration
+ ├── team2/
+ │   └── .tag-conversationsrc  # Team 2 specific configuration
+ └── .tag-conversationsrc      # Project-wide default configuration
+ ```
+ 
+ When running the CLI in a subdirectory, it will merge configurations from all parent directories, with closer directories taking precedence.
+ 
+ ## Configuration Best Practices
+ 
+ 1. **Use Project Configuration**: Store project-specific settings in a version-controlled configuration file
+ 2. **Use Environment Variables**: Store sensitive information like API keys in environment variables or .env files (excluded from version control)
+ 3. **Create Profiles**: Define profiles for common use cases to simplify command execution
+ 4. **Validate Settings**: Always validate custom configuration to catch errors early
+ 5. **Document Changes**: Comment configuration files to explain non-obvious settings
+ 6. **Version Control**: Include example configuration files in version control for easy onboarding 
```

---

Your Lordship, I've created a comprehensive CLI documentation set for Obsidian Magic. The documentation now includes all previously missing documents plus additional ones:

1. **Created workflow-orchestration.md**: Detailed documentation on the CLI's workflow orchestration system, including processing modes, pipeline steps, concurrency management, and file selection strategies.

2. **Created benchmarking.md**: Comprehensive guide to the benchmarking capabilities, including benchmark datasets, metrics, reports, model comparison, and stress testing.

3. **Created yargs-implementation.md**: Technical implementation details of how Yargs is used in the CLI, covering command structure, option definitions, middleware, and best practices.

4. **Created error-handling.md**: Detailed documentation on error handling strategies, including error categorization, validation, API error handling, and recovery mechanisms.

5. **Created interactive-ui.md**: Guide to the CLI's interactive UI features, including terminal components, tag reviewing, progress visualization, and keyboard controls.

6. **Created configuration-reference.md**: Complete reference for the configuration system, including file formats, environment variables, profiles, and validation.

7. **Enhanced cli-overview.md**: Updated to reference all the new documents and provide a more comprehensive overview of the CLI.

All documents follow a consistent structure with detailed explanations, code examples, and usage patterns. The documentation provides both high-level overviews and detailed technical information for different user needs.

Your Humble Servant, Sebastien

---

_**User**_

Update any relevant @rules 

---



---

